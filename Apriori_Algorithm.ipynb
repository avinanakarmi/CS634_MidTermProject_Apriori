{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Commands to install required packages**\n",
        "- pip install pandas mlxtend numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUSYoa3kullz"
      },
      "source": [
        "**Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFjvWpm5y4fE",
        "outputId": "4ec9753a-bb39-472d-91d0-450f17255562"
      },
      "outputs": [],
      "source": [
        "def do_while(check_condition, action):\n",
        "  action()\n",
        "  while check_condition():\n",
        "    action()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0WKcS4qy6W_"
      },
      "source": [
        "# Data Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{1: 'Best Buy', 2: 'Amazon', 3: 'Generic', 4: 'Nike', 5: 'K-Mart', 6: 'Custom'}\n"
          ]
        }
      ],
      "source": [
        "### Listing all datasets stored in the ./datasets folder\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "path = './datasets/'\n",
        "\n",
        "datasets = [f.split('.')[0] for f in listdir(path) if isfile(join(path, f)) and f.split('.')[1] == 'csv']\n",
        "datasets = dict(zip(range(1, len(datasets) + 1), datasets))\n",
        "print(datasets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPCRIjyWurSs",
        "outputId": "a46b9487-9a67-4efc-8546-67b07a8a4061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Select a dataset: \n",
            "\n",
            "1 :  Best Buy\n",
            "2 :  Amazon\n",
            "3 :  Generic\n",
            "4 :  Nike\n",
            "5 :  K-Mart\n",
            "6 :  Custom\n",
            "You selected:  Best Buy\n"
          ]
        }
      ],
      "source": [
        "dataset = 0\n",
        "attempted = 0\n",
        "\n",
        "def read_dataset_input():\n",
        "  \"\"\"\n",
        "      - On the first attempt, prompts the user to select a dataset.\n",
        "      - On subsequent attempts, informs the user of an invalid selection if needed.\n",
        "      - If the user's input matches a key in the `datasets` dictionary, it prints the selected dataset.\n",
        "      \n",
        "      Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "  global attempted, dataset\n",
        "  print(\"Invalid selection. Try again. \\n\") if attempted > 0 else print(\"Select a dataset: \\n\")\n",
        "  for k,v in datasets.items():\n",
        "    print(k, ': ', v)\n",
        "  attempted += 1\n",
        "  dataset = int(input())\n",
        "  if dataset in datasets.keys(): print(\"You selected: \", datasets[dataset])\n",
        "\n",
        "input_read_condition = lambda: dataset not in datasets.keys()\n",
        "do_while(input_read_condition, read_dataset_input)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFzgAedDxEO_"
      },
      "source": [
        "# Defining support and confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekDkrNdzxH6S",
        "outputId": "ab7715c4-2e33-4f86-81f1-4397be4ac3e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating association rules for  Best Buy  dataset with support:  0.5  and confidence:  0.5\n"
          ]
        }
      ],
      "source": [
        "support = None\n",
        "confidence = None\n",
        "\n",
        "def read_threshold():\n",
        "  \"\"\"\n",
        "    - Prompts the user to enter a value for the support threshold.\n",
        "    - Prompts the user to enter a value for the confidence threshold.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  global support, confidence\n",
        "  support = input(\"Enter support threshold between 0.1 to 100 : \")\n",
        "  confidence = input(\"Enter confidence threshold between 0.1 to 100 : \")\n",
        "\n",
        "def threshold_read_condition():\n",
        "  \"\"\"\n",
        "    - Attempts to convert `support` and `confidence` to floats.\n",
        "    - If conversion fails (i.e., invalid input types), prints an error message and returns True to\n",
        "      indicate the need for retrying.\n",
        "    - Checks whether the values for `support` and `confidence` fall within the valid range [0, 1].\n",
        "    - Returns False if both values are valid, otherwise returns True and prints an error message.\n",
        "\n",
        "    Returns:\n",
        "    bool: True if input is invalid (either due to type or out-of-range values), False otherwise.\n",
        "  \"\"\"\n",
        "  global support, confidence\n",
        "  try:\n",
        "    support = float(support)\n",
        "    confidence = float(confidence)\n",
        "  except ValueError:\n",
        "    print(\"Invalid input type. Try again.\")\n",
        "    return True\n",
        "  if 0 < support <= 1 and 0 < confidence <= 1:\n",
        "    return False\n",
        "  print(\"Invalid input range. Try again.\")\n",
        "  return True\n",
        "do_while(threshold_read_condition, read_threshold)\n",
        "\n",
        "print(\"Generating association rules for \", datasets[dataset], \" dataset with support: \", support, \" and confidence: \", confidence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8jgwrT466-S"
      },
      "source": [
        "# Reading Transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtzxaB7Z7uwt",
        "outputId": "26ff34f0-db27-4a10-cc88-5ad45e9c2eb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          Transaction\n",
            "0   Desk Top, Printer, Flash Drive, Microsoft Offi...\n",
            "1   Lab Top, Flash Drive, Microsoft Office, Lab To...\n",
            "2   Lab Top, Printer, Flash Drive, Microsoft Offic...\n",
            "3   Lab Top, Printer, Flash Drive, Anti-Virus, Ext...\n",
            "4     Lab Top, Flash Drive, Lab Top Case, Anti-Virus \n",
            "5    Lab Top, Printer, Flash Drive, Microsoft Office \n",
            "6   Desk Top, Printer, Flash Drive, Microsoft Office \n",
            "7           Lab Top, External Hard-Drive, Anti-Virus \n",
            "8   Desk Top, Printer, Flash Drive, Microsoft Offi...\n",
            "9   Digital Camera , Lab Top, Desk Top, Printer, F...\n",
            "10  Lab Top, Desk Top, Lab Top Case, External Hard...\n",
            "11  Digital Camera , Lab Top, Lab Top Case, Extern...\n",
            "12                         Digital Camera , Speakers \n",
            "13  Digital Camera , Desk Top, Printer, Flash Driv...\n",
            "14  Printer, Flash Drive, Microsoft Office, Anti-V...\n",
            "15  Digital Camera, Flash Drive, Microsoft Office,...\n",
            "16            Digital Camera , Lab Top, Lab Top Case \n",
            "17           Digital Camera , Lab Top Case, Speakers \n",
            "18  Digital Camera , Lab Top, Printer, Flash Drive...\n",
            "19  Digital Camera , Lab Top, Speakers, Anti-Virus...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "raw_dataset = pd.read_csv('./datasets/' + datasets[dataset] + '.csv', usecols=[1])\n",
        "transactions_list = [transaction[0].split(',') for transaction in raw_dataset.values.tolist()]\n",
        "transactions_list = [[item.strip() for item in transaction] for transaction in transactions_list]\n",
        "\n",
        "print(raw_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FsPFn9d6nkw"
      },
      "source": [
        "# Arpiori Using mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uilnmwYuCO4q",
        "outputId": "3eb84e8e-a663-480f-b529-dc62d76221e7"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgO5jaqA6xqf",
        "outputId": "2ecfdac4-9576-4151-ceca-36047ca65b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Antecedents         Consequents  Support  Confidence\n",
            "0   (Microsoft Office)       (Flash Drive)     0.55    1.000000\n",
            "1        (Flash Drive)  (Microsoft Office)     0.55    0.846154\n",
            "2        (Flash Drive)           (Printer)     0.50    0.769231\n",
            "3            (Printer)       (Flash Drive)     0.50    1.000000\n",
            "4         (Anti-Virus)       (Flash Drive)     0.50    0.714286\n",
            "5        (Flash Drive)        (Anti-Virus)     0.50    0.769231\n",
            "6            (Lab Top)      (Lab Top Case)     0.50    0.833333\n",
            "7       (Lab Top Case)           (Lab Top)     0.50    0.714286\n",
            "8            (Lab Top)        (Anti-Virus)     0.50    0.833333\n",
            "9         (Anti-Virus)           (Lab Top)     0.50    0.714286\n",
            "10      (Lab Top Case)        (Anti-Virus)     0.60    0.857143\n",
            "11        (Anti-Virus)      (Lab Top Case)     0.60    0.857143\n",
            "Time taken:  0.008301973342895508  seconds\n"
          ]
        }
      ],
      "source": [
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "all_items = set(item for sublist in transactions_list for item in sublist)\n",
        "\n",
        "df = pd.DataFrame([{item: (item in transaction) for item in all_items} for transaction in transactions_list])\n",
        "\n",
        "frequent_itemsets = apriori(df, min_support=support, use_colnames=True)\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence)\n",
        "\n",
        "rules_sorted = rules.sort_values(by='lift', ascending=False)\n",
        "\n",
        "rules_filtered = rules[['antecedents', 'consequents', 'support', 'confidence']]\n",
        "rules_filtered.columns = ['Antecedents', 'Consequents', 'Support', 'Confidence']\n",
        "\n",
        "print(rules_filtered)\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Time taken: \", end_time - start_time, \" seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSdpGqyN6yOg"
      },
      "source": [
        "# FP-growth Using mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gUsbdkTBVmF",
        "outputId": "676f7409-b35a-4532-e0b4-490d33791814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Antecedents         Consequents  Support  Confidence\n",
            "0         (Anti-Virus)       (Flash Drive)     0.50    0.714286\n",
            "1        (Flash Drive)        (Anti-Virus)     0.50    0.769231\n",
            "2   (Microsoft Office)       (Flash Drive)     0.55    1.000000\n",
            "3        (Flash Drive)  (Microsoft Office)     0.55    0.846154\n",
            "4        (Flash Drive)           (Printer)     0.50    0.769231\n",
            "5            (Printer)       (Flash Drive)     0.50    1.000000\n",
            "6       (Lab Top Case)        (Anti-Virus)     0.60    0.857143\n",
            "7         (Anti-Virus)      (Lab Top Case)     0.60    0.857143\n",
            "8            (Lab Top)      (Lab Top Case)     0.50    0.833333\n",
            "9       (Lab Top Case)           (Lab Top)     0.50    0.714286\n",
            "10           (Lab Top)        (Anti-Virus)     0.50    0.833333\n",
            "11        (Anti-Virus)           (Lab Top)     0.50    0.714286\n",
            "Time taken:  0.00527191162109375  seconds\n"
          ]
        }
      ],
      "source": [
        "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
        "\n",
        "start_time = time.time()\n",
        "frequent_itemsets = fpgrowth(df, min_support=support, use_colnames=True)\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence)\n",
        "\n",
        "rules_filtered = rules[['antecedents', 'consequents', 'support', 'confidence']]\n",
        "rules_filtered.columns = ['Antecedents', 'Consequents', 'Support', 'Confidence']\n",
        "\n",
        "print(rules_filtered)\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Time taken: \", end_time - start_time, \" seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew_wZKGRzc3-"
      },
      "source": [
        "# Implementing Apiori"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6OSENb0dtxW"
      },
      "source": [
        "**Generating frequent items**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsImyhRzzfjC",
        "outputId": "fd19d14d-86ad-4a7c-b387-04b5d82bae9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('Microsoft Office',) 0.55\n",
            "('Speakers',) 0.55\n",
            "('Flash Drive',) 0.65\n",
            "('Anti-Virus',) 0.7\n",
            "('Printer',) 0.5\n",
            "('Lab Top',) 0.6\n",
            "('Lab Top Case',) 0.7\n",
            "('Microsoft Office', 'Flash Drive') 0.55\n",
            "('Flash Drive', 'Printer') 0.5\n",
            "('Flash Drive', 'Anti-Virus') 0.5\n",
            "('Lab Top', 'Lab Top Case') 0.5\n",
            "('Lab Top', 'Anti-Virus') 0.5\n",
            "('Lab Top Case', 'Anti-Virus') 0.6\n"
          ]
        }
      ],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "min_sup = support * len(transactions_list)\n",
        "freq_itemset_support = {}\n",
        "\n",
        "\n",
        "def count_item_freq(itemsets):\n",
        "  \"\"\"\n",
        "    - Iterates over each transaction in `transactions_list` and checks whether each itemset\n",
        "      is present in the transaction.\n",
        "    - If all items in an itemset are found within a transaction, increments the count for that\n",
        "      itemset in the `itemset_support` dictionary.\n",
        "    - Uses the `itemset_support` dictionary to store the frequency of each itemset.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where the keys are itemsets and the values are their corresponding frequencies.\n",
        "  \"\"\"\n",
        "  itemset_support = {}\n",
        "  for transaction in transactions_list:\n",
        "    for itemset in itemsets:\n",
        "      for item in itemset:\n",
        "        if item not in transaction:\n",
        "          break\n",
        "      else:\n",
        "        itemset_support[itemset] = itemset_support.get(itemset, 0) + 1\n",
        "  return itemset_support\n",
        "\n",
        "\n",
        "def prune_items(last_freq_itemset):\n",
        "  \"\"\"\n",
        "    - Iterates over each itemset and its support in `last_freq_itemset`.\n",
        "    - Filters out itemsets whose support is below `min_sup`.\n",
        "    - For each retained itemset, calculates its relative support as the ratio of its count to the\n",
        "      total number of transactions.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where the keys are itemsets and the values are their relative support\n",
        "          (calculated as support count divided by the total number of transactions), for itemsets\n",
        "          that meet or exceed the minimum support threshold.\n",
        "  \"\"\"\n",
        "  return {itemset:(sup/len(transactions_list)) for itemset,sup in last_freq_itemset.items() if sup >= min_sup}\n",
        "\n",
        "def make_n_itemset(n_itemset):\n",
        "  \"\"\"\n",
        "    - Extracts unique items from the provided `n_itemset`.\n",
        "      - Creates (n+1)-itemsets by combining these unique items.\n",
        "      - Returns a list of all possible (n+1)-itemsets.\n",
        "\n",
        "      Example:\n",
        "      If `n_itemset` contains itemsets like [('A', 'B'), ('A', 'C')], the function will generate\n",
        "      (n+1)-itemsets like [('A', 'B', 'C')] if 'A', 'B', 'C' are the unique items.\n",
        "  \"\"\"\n",
        "  n = len(n_itemset[0])\n",
        "  return list(combinations(list(set(item for s in n_itemset for item in s)), n + 1))\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "new_item_set_list = list(set((item,) for transaction in transactions_list for item in transaction))\n",
        "\n",
        "while new_item_set_list:\n",
        "  itemset_support = count_item_freq(new_item_set_list)\n",
        "  freq_itemsets = prune_items(itemset_support)\n",
        "  freq_itemset_support.update(freq_itemsets)\n",
        "  if len(freq_itemsets) == 0:\n",
        "    break\n",
        "  new_item_set_list = make_n_itemset(list(freq_itemsets.keys()))\n",
        "\n",
        "for itemset, sup in freq_itemset_support.items():\n",
        "  print(itemset, sup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2kRxuebh2fV"
      },
      "source": [
        "**Mining Association Rules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvMDzLI9h5mw",
        "outputId": "fab545a0-4b96-4c3e-cb86-8fe1f1b6865f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rule  1 :  ('Microsoft Office',) -> ('Flash Drive',)\n",
            "Confidence:  100.0 %\n",
            "Support:  55.00000000000001 %\n",
            "\n",
            "\n",
            "Rule  2 :  ('Flash Drive',) -> ('Microsoft Office',)\n",
            "Confidence:  84.61538461538461 %\n",
            "Support:  55.00000000000001 %\n",
            "\n",
            "\n",
            "Rule  3 :  ('Flash Drive',) -> ('Printer',)\n",
            "Confidence:  76.92307692307692 %\n",
            "Support:  50.0 %\n",
            "\n",
            "\n",
            "Rule  4 :  ('Printer',) -> ('Flash Drive',)\n",
            "Confidence:  100.0 %\n",
            "Support:  50.0 %\n",
            "\n",
            "\n",
            "Rule  5 :  ('Flash Drive',) -> ('Anti-Virus',)\n",
            "Confidence:  76.92307692307692 %\n",
            "Support:  50.0 %\n",
            "\n",
            "\n",
            "Rule  6 :  ('Anti-Virus',) -> ('Flash Drive',)\n",
            "Confidence:  71.42857142857143 %\n",
            "Support:  50.0 %\n",
            "\n",
            "\n",
            "Rule  7 :  ('Lab Top',) -> ('Lab Top Case',)\n",
            "Confidence:  83.33333333333334 %\n",
            "Support:  50.0 %\n",
            "\n",
            "\n",
            "Rule  8 :  ('Lab Top Case',) -> ('Lab Top',)\n",
            "Confidence:  71.42857142857143 %\n",
            "Support:  50.0 %\n",
            "\n",
            "\n",
            "Rule  9 :  ('Lab Top',) -> ('Anti-Virus',)\n",
            "Confidence:  83.33333333333334 %\n",
            "Support:  50.0 %\n",
            "\n",
            "\n",
            "Rule  10 :  ('Anti-Virus',) -> ('Lab Top',)\n",
            "Confidence:  71.42857142857143 %\n",
            "Support:  50.0 %\n",
            "\n",
            "\n",
            "Rule  11 :  ('Lab Top Case',) -> ('Anti-Virus',)\n",
            "Confidence:  85.71428571428572 %\n",
            "Support:  60.0 %\n",
            "\n",
            "\n",
            "Rule  12 :  ('Anti-Virus',) -> ('Lab Top Case',)\n",
            "Confidence:  85.71428571428572 %\n",
            "Support:  60.0 %\n",
            "\n",
            "\n",
            "Time taken:  0.009391069412231445  seconds\n"
          ]
        }
      ],
      "source": [
        "index = 1\n",
        "for itemset, sup in freq_itemset_support.items():\n",
        "  if len(itemset) < 2:\n",
        "    continue\n",
        "  for i in range(1, len(itemset)):\n",
        "    for antecedent in combinations(itemset, i):\n",
        "      consequent = tuple(set(itemset) - set(antecedent))\n",
        "      conf = freq_itemset_support[itemset] / freq_itemset_support[antecedent]\n",
        "      if conf >= confidence:\n",
        "        print(\"Rule \", index, \": \", antecedent, \"->\", consequent)\n",
        "        print(\"Confidence: \", conf*100, \"%\")\n",
        "        print(\"Support: \", freq_itemset_support[itemset]*100, \"%\")\n",
        "        print(\"\\n\")\n",
        "        index += 1\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Time taken: \", end_time - start_time, \" seconds\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
