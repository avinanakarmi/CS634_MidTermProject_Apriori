{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Commands to install required packages**\n",
        "- pip install pandas mlxtend numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUSYoa3kullz"
      },
      "source": [
        "**Utility functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFjvWpm5y4fE",
        "outputId": "4ec9753a-bb39-472d-91d0-450f17255562"
      },
      "outputs": [],
      "source": [
        "def do_while(check_condition, action):\n",
        "  action()\n",
        "  while check_condition():\n",
        "    action()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0WKcS4qy6W_"
      },
      "source": [
        "# Data Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPCRIjyWurSs",
        "outputId": "a46b9487-9a67-4efc-8546-67b07a8a4061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Select a dataset: \n",
            "\n",
            "You selected:  Generic\n"
          ]
        }
      ],
      "source": [
        "datasets = {\n",
        "  '1': 'Amazon',\n",
        "  '2': 'Best Buy',\n",
        "  '3': 'K-Mart',\n",
        "  '4': 'Nike',\n",
        "  '5': 'Custom',\n",
        "  '6': 'Generic',\n",
        "}\n",
        "\n",
        "\n",
        "dataset = 0\n",
        "attempted = 0\n",
        "\n",
        "def read_dataset_input():\n",
        "  \"\"\"\n",
        "      - On the first attempt, prompts the user to select a dataset.\n",
        "      - On subsequent attempts, informs the user of an invalid selection if needed.\n",
        "      - If the user's input matches a key in the `datasets` dictionary, it prints the selected dataset.\n",
        "      \n",
        "      Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "  global attempted, dataset\n",
        "  print(\"Invalid selection. Try again. \\n\") if attempted > 0 else print(\"Select a dataset: \\n\")\n",
        "  attempted += 1\n",
        "  dataset = input(\" 1. Amazon \\n 2. Best Buy \\n 3. K-mart \\n 4. Nike \\n 5. Custom \\n 6. Generic \\n\")\n",
        "  if dataset in datasets.keys(): print(\"You selected: \", datasets[dataset])\n",
        "\n",
        "input_read_condition = lambda: dataset not in datasets.keys()\n",
        "do_while(input_read_condition, read_dataset_input)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFzgAedDxEO_"
      },
      "source": [
        "# Defining support and confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekDkrNdzxH6S",
        "outputId": "ab7715c4-2e33-4f86-81f1-4397be4ac3e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating association rules for  Generic  dataset with support:  0.46  and confidence:  0.77\n"
          ]
        }
      ],
      "source": [
        "support = None\n",
        "confidence = None\n",
        "\n",
        "def read_threshold():\n",
        "  \"\"\"\n",
        "    - Prompts the user to enter a value for the support threshold.\n",
        "    - Prompts the user to enter a value for the confidence threshold.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  global support, confidence\n",
        "  support = input(\"Enter support threshold between 0.1 to 100 : \")\n",
        "  confidence = input(\"Enter confidence threshold between 0.1 to 100 : \")\n",
        "\n",
        "def threshold_read_condition():\n",
        "  \"\"\"\n",
        "    - Attempts to convert `support` and `confidence` to floats.\n",
        "    - If conversion fails (i.e., invalid input types), prints an error message and returns True to\n",
        "      indicate the need for retrying.\n",
        "    - Checks whether the values for `support` and `confidence` fall within the valid range [0, 1].\n",
        "    - Returns False if both values are valid, otherwise returns True and prints an error message.\n",
        "\n",
        "    Returns:\n",
        "    bool: True if input is invalid (either due to type or out-of-range values), False otherwise.\n",
        "  \"\"\"\n",
        "  global support, confidence\n",
        "  try:\n",
        "    support = float(support)\n",
        "    confidence = float(confidence)\n",
        "  except ValueError:\n",
        "    print(\"Invalid input type. Try again.\")\n",
        "    return True\n",
        "  if 0 < support <= 1 and 0 < confidence <= 1:\n",
        "    return False\n",
        "  print(\"Invalid input range. Try again.\")\n",
        "  return True\n",
        "do_while(threshold_read_condition, read_threshold)\n",
        "\n",
        "print(\"Generating association rules for \", datasets[dataset], \" dataset with support: \", support, \" and confidence: \", confidence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8jgwrT466-S"
      },
      "source": [
        "# Reading Transactions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtzxaB7Z7uwt",
        "outputId": "26ff34f0-db27-4a10-cc88-5ad45e9c2eb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Transactions\n",
            "0         A, B, C \n",
            "1         A, B, C \n",
            "2      A, B, C, D \n",
            "3   A, B, C, D, E \n",
            "4      A, B, D, E \n",
            "5         A, D, E \n",
            "6            A, E \n",
            "7            A, E \n",
            "8         A, C, E \n",
            "9         A, C, E \n",
            "10        A, C, E \n",
            "11      A, B, C, E\n",
            "12         A, B, D\n",
            "13      B, C, D, E\n",
            "14         A, C, D\n",
            "15            B, E\n",
            "16         A, B, C\n",
            "17            A, D\n",
            "18         B, C, E\n",
            "19      A, C, D, E\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "raw_dataset = pd.read_csv('./datasets/' + datasets[dataset] + '.csv', usecols=[1])\n",
        "transactions_list = [transaction[0].split(',') for transaction in raw_dataset.values.tolist()]\n",
        "transactions_list = [[item.strip() for item in transaction] for transaction in transactions_list]\n",
        "\n",
        "print(raw_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FsPFn9d6nkw"
      },
      "source": [
        "# Arpiori Using mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uilnmwYuCO4q",
        "outputId": "3eb84e8e-a663-480f-b529-dc62d76221e7"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgO5jaqA6xqf",
        "outputId": "2ecfdac4-9576-4151-ceca-36047ca65b9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Antecedents Consequents  Support  Confidence\n",
            "0         (C)         (A)     0.55    0.846154\n",
            "Time taken:  0.0055561065673828125  seconds\n"
          ]
        }
      ],
      "source": [
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "all_items = set(item for sublist in transactions_list for item in sublist)\n",
        "\n",
        "df = pd.DataFrame([{item: (item in transaction) for item in all_items} for transaction in transactions_list])\n",
        "\n",
        "frequent_itemsets = apriori(df, min_support=support, use_colnames=True)\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence)\n",
        "\n",
        "rules_sorted = rules.sort_values(by='lift', ascending=False)\n",
        "\n",
        "rules_filtered = rules[['antecedents', 'consequents', 'support', 'confidence']]\n",
        "rules_filtered.columns = ['Antecedents', 'Consequents', 'Support', 'Confidence']\n",
        "\n",
        "print(rules_filtered)\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Time taken: \", end_time - start_time, \" seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSdpGqyN6yOg"
      },
      "source": [
        "# FP-growth Using mlxtend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gUsbdkTBVmF",
        "outputId": "676f7409-b35a-4532-e0b4-490d33791814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Antecedents Consequents  Support  Confidence\n",
            "0         (C)         (A)     0.55    0.846154\n",
            "Time taken:  0.0033380985260009766  seconds\n"
          ]
        }
      ],
      "source": [
        "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
        "\n",
        "start_time = time.time()\n",
        "frequent_itemsets = fpgrowth(df, min_support=support, use_colnames=True)\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=confidence)\n",
        "\n",
        "rules_filtered = rules[['antecedents', 'consequents', 'support', 'confidence']]\n",
        "rules_filtered.columns = ['Antecedents', 'Consequents', 'Support', 'Confidence']\n",
        "\n",
        "print(rules_filtered)\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Time taken: \", end_time - start_time, \" seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew_wZKGRzc3-"
      },
      "source": [
        "# Implementing Apiori"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6OSENb0dtxW"
      },
      "source": [
        "**Generating frequent items**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsImyhRzzfjC",
        "outputId": "fd19d14d-86ad-4a7c-b387-04b5d82bae9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('A',) 0.85\n",
            "('C',) 0.65\n",
            "('B',) 0.55\n",
            "('E',) 0.65\n",
            "('A', 'C') 0.55\n",
            "('A', 'E') 0.5\n"
          ]
        }
      ],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "min_sup = support * len(transactions_list)\n",
        "freq_itemset_support = {}\n",
        "\n",
        "\n",
        "def count_item_freq(itemsets):\n",
        "  \"\"\"\n",
        "    - Iterates over each transaction in `transactions_list` and checks whether each itemset\n",
        "      is present in the transaction.\n",
        "    - If all items in an itemset are found within a transaction, increments the count for that\n",
        "      itemset in the `itemset_support` dictionary.\n",
        "    - Uses the `itemset_support` dictionary to store the frequency of each itemset.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where the keys are itemsets and the values are their corresponding frequencies.\n",
        "  \"\"\"\n",
        "  itemset_support = {}\n",
        "  for transaction in transactions_list:\n",
        "    for itemset in itemsets:\n",
        "      for item in itemset:\n",
        "        if item not in transaction:\n",
        "          break\n",
        "      else:\n",
        "        itemset_support[itemset] = itemset_support.get(itemset, 0) + 1\n",
        "  return itemset_support\n",
        "\n",
        "\n",
        "def prune_items(last_freq_itemset):\n",
        "  \"\"\"\n",
        "    - Iterates over each itemset and its support in `last_freq_itemset`.\n",
        "    - Filters out itemsets whose support is below `min_sup`.\n",
        "    - For each retained itemset, calculates its relative support as the ratio of its count to the\n",
        "      total number of transactions.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where the keys are itemsets and the values are their relative support\n",
        "          (calculated as support count divided by the total number of transactions), for itemsets\n",
        "          that meet or exceed the minimum support threshold.\n",
        "  \"\"\"\n",
        "  return {itemset:(sup/len(transactions_list)) for itemset,sup in last_freq_itemset.items() if sup >= min_sup}\n",
        "\n",
        "def make_n_itemset(n_itemset):\n",
        "  \"\"\"\n",
        "    - Extracts unique items from the provided `n_itemset`.\n",
        "      - Creates (n+1)-itemsets by combining these unique items.\n",
        "      - Returns a list of all possible (n+1)-itemsets.\n",
        "\n",
        "      Example:\n",
        "      If `n_itemset` contains itemsets like [('A', 'B'), ('A', 'C')], the function will generate\n",
        "      (n+1)-itemsets like [('A', 'B', 'C')] if 'A', 'B', 'C' are the unique items.\n",
        "  \"\"\"\n",
        "  n = len(n_itemset[0])\n",
        "  return list(combinations(list(set(item for s in n_itemset for item in s)), n + 1))\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "new_item_set_list = list(set((item,) for transaction in transactions_list for item in transaction))\n",
        "\n",
        "while new_item_set_list:\n",
        "  itemset_support = count_item_freq(new_item_set_list)\n",
        "  freq_itemsets = prune_items(itemset_support)\n",
        "  freq_itemset_support.update(freq_itemsets)\n",
        "  if len(freq_itemsets) == 0:\n",
        "    break\n",
        "  new_item_set_list = make_n_itemset(list(freq_itemsets.keys()))\n",
        "\n",
        "for itemset, sup in freq_itemset_support.items():\n",
        "  print(itemset, sup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2kRxuebh2fV"
      },
      "source": [
        "**Mining Association Rules**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvMDzLI9h5mw",
        "outputId": "fab545a0-4b96-4c3e-cb86-8fe1f1b6865f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rule  1 :  ('C',) -> ('A',)\n",
            "Confidence:  84.61538461538461 %\n",
            "Support:  55.00000000000001 %\n",
            "\n",
            "\n",
            "Time taken:  0.005317211151123047  seconds\n"
          ]
        }
      ],
      "source": [
        "index = 1\n",
        "for itemset, sup in freq_itemset_support.items():\n",
        "  if len(itemset) < 2:\n",
        "    continue\n",
        "  for i in range(1, len(itemset)):\n",
        "    for antecedent in combinations(itemset, i):\n",
        "      consequent = tuple(set(itemset) - set(antecedent))\n",
        "      conf = freq_itemset_support[itemset] / freq_itemset_support[antecedent]\n",
        "      if conf >= confidence:\n",
        "        print(\"Rule \", index, \": \", antecedent, \"->\", consequent)\n",
        "        print(\"Confidence: \", conf*100, \"%\")\n",
        "        print(\"Support: \", freq_itemset_support[itemset]*100, \"%\")\n",
        "        print(\"\\n\")\n",
        "        index += 1\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"Time taken: \", end_time - start_time, \" seconds\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
